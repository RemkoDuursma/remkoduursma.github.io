<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Temporal on Remko Duursma</title>
    <link>http://www.remkoduursma.com/post</link>
    <description>Recent content on Remko Duursma</description>
    <generator>Hugo, blogdown, rmarkdown</generator>
    <language>en-US</language>
    <lastBuildDate>Wed, 24 Jan 2018 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/temporal/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Analysis of fuel prices in New South Wales</title>
      <link>/post/2018-01-24-fuelprices1/</link>
      <pubDate>Wed, 24 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-01-24-fuelprices1/</guid>
      <description>&lt;div id=&#34;how-do-petrol-prices-vary-across-the-state&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;em&gt;How do petrol prices vary across the state?&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;The price of fuel at service stations varies tremendously, both in space - across the large Australian state of New South Wales, and time - with surprising patterns. In this post I begin my quest to understand how fuel price varies, what factors explain its fluctuation over time and spatial variation. Obviously it would be nice to be able to know where to drive for cheaper fuel (what kind of areas are cheaper?), and when to fill up (should I wait until Thursday?).&lt;/p&gt;
&lt;p&gt;Since August 2016, the NSW government runs the &lt;a href=&#34;https://www.fuelcheck.nsw.gov.au/app&#34;&gt;FuelCheck service&lt;/a&gt;, which allows monitoring of fuel prices &lt;em&gt;in real time&lt;/em&gt;. Several apps tap into this publicly available API, allowing users to find the cheapest fuel in the neighborhood, or inspect some simple graphs of fuel price over time.&lt;/p&gt;
&lt;p&gt;As an additional service, (nearly) daily prices of all types of fuel, all brands of service stations, and &lt;strong&gt;all locations&lt;/strong&gt; across the state can be downloaded from the &lt;a href=&#34;https://data.nsw.gov.au/&#34;&gt;NSW Data portal&lt;/a&gt;, currently from August 2016 to October 2017. The dataset contains over one million records, for over 2000 service stations, and 11 fuel types.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;img/fuelcheck_web.png&#34; /&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;approach&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Approach&lt;/h3&gt;
&lt;p&gt;This is the first in a series of posts on this hobby project to find out if we can &lt;em&gt;predict fuel prices in space and time&lt;/em&gt;. What I want to know is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Is fuel cheaper on a particular day of the week? It is a widely-held belief that fuel prices are more expensive on the day that everyone receives their weekly paycheck (Thursday), but do the data support this?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Across the state, how does fuel price vary and why? Quick inspection of the data shows that remote areas are more expensive; how do we summarize that, and what else matters? As roughly 5 out of 7.5 million people in NSW live in the Sydney metropolitan area - that is two thirds of the population on 1.5% of the land area - I will look at Sydney and non-Sydney data separately for much of this analysis.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Instead of just showing results, these posts are very much about getting into the details of the R code to generate them. I will use &lt;code&gt;dplyr&lt;/code&gt;, &lt;code&gt;forcats&lt;/code&gt;, &lt;code&gt;ggplot2&lt;/code&gt;, &lt;code&gt;deldir&lt;/code&gt; (Voronoi polygons), &lt;code&gt;SDraw&lt;/code&gt; (better Voronoi polygons), &lt;code&gt;oz&lt;/code&gt; (quick maps of Australia), &lt;code&gt;rgeos&lt;/code&gt;, and &lt;code&gt;magicaxis&lt;/code&gt; throughout the code.&lt;/p&gt;
&lt;p&gt;But before we get started, here is a taste of what’s to come:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-01-24-fuelprices1_files/figure-html/figure1-1.png&#34; width=&#34;600px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The data show an interesting fluctuation in fuel prices, &lt;a href=&#34;https://www.accc.gov.au/consumers/petrol-diesel-lpg/petrol-price-cycles#petrol-prices-in-sydney&#34;&gt;which can be viewed on this official site as well&lt;/a&gt;, but the fluctuations are on much longer timescales than weekly. Zooming in on a two-month period in 2017, we see the peculiar pattern of a very sudden jump in fuel prices, followed by a gradual decline over the period of a month or so.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-01-24-fuelprices1_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;400px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;getting-the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Getting the Data&lt;/h1&gt;
&lt;p&gt;The FuelCheck service in New South Wales, Australia, provides real-time data on fuel prices at service stations across the state. &lt;a href=&#34;https://data.nsw.gov.au/data/dataset/fuel-check&#34;&gt;This page&lt;/a&gt; contains information, as well as monthly files containing fuel prices for all service stations, for all fuel types. The first step is to download all &lt;code&gt;xlsx&lt;/code&gt; files, and save them locally. We then use &lt;code&gt;readxl&lt;/code&gt; to read them all, and &lt;code&gt;dplyr&lt;/code&gt; to tidy things up.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pacman::p_load(readxl, dplyr, lubridate, ggmap,
               SDraw, deldir, sp, rgeos, geosphere,
               janitor, magicaxis)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Don&amp;#39;t have to run this, since the clean raw data is bundled
# in the fuelpricensw package (github: remkoduursma/fuelpricensw)
if(FALSE){
  readx &amp;lt;- function(x){
    res &amp;lt;-  read_excel(x)
    if(names(res)[2] == &amp;quot;X__1&amp;quot;){
      res &amp;lt;-  read_excel(x, skip=1)   
    }
    
    res &amp;lt;- mutate(res, Postcode  = as.numeric(Postcode))
    if(&amp;quot;FuelType&amp;quot; %in% names(res)){
      res &amp;lt;- rename(res, FuelCode = FuelType)
    }
    
  return(res)
  }
  
  fuel &amp;lt;- lapply(dir(&amp;quot;rawdata&amp;quot;, pattern=&amp;quot;xlsx&amp;quot;, full.names = TRUE), readx) %&amp;gt;%
    bind_rows %&amp;gt;%
    mutate(DateTime = ymd_hms(PriceUpdatedDate),
           Date = as.Date(DateTime)) %&amp;gt;%
    dplyr::select(-PriceUpdatedDate) %&amp;gt;%
    filter(Price &amp;lt; 500)

}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can skip this step as I have bundled the clean dataset in the R package &lt;code&gt;fuelpricensw&lt;/code&gt;, which is available on &lt;a href=&#34;https://github.com/RemkoDuursma/fuelpricensw&#34;&gt;this Github repos&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;quot;remkoduursma/fuelpricensw&amp;quot;)
library(fuelpricensw)
data(fuel)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;feature-engineering-spatial-components&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Feature engineering : spatial components&lt;/h2&gt;
&lt;p&gt;The remainder of this first part on fuel price analysis will look at the spatial component of fuel prices, and we will calculate some spatial features based on the locations of the service stations. The first step, then, is to get the latitude and longitude for each station based on the address.&lt;/p&gt;
&lt;p&gt;Here I used Google’s geocode service, as made easily available in the &lt;code&gt;ggmap&lt;/code&gt; package. The service does not always return a proper result, even though when typing in the same address in &lt;code&gt;maps.google.com&lt;/code&gt; might give the right address.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;latcache &amp;lt;- &amp;quot;data/Fuel_NSW_addresses_latlon.csv&amp;quot;
if(!file.exists(latcache)){

  # Unique addresses to look up.
  addr &amp;lt;- unique(fuel$Address)
  
  # After some failures, I found that extra info between () messes with 
  # the geocode service. Remove them.
  addr_re &amp;lt;- gsub(&amp;quot;\\(.+\\)&amp;quot;, &amp;quot;&amp;quot;, addr)
  
  # Get rid of &amp;quot;Cnr of ...,&amp;quot;, but not when address starts with it.
  addr_re &amp;lt;- gsub(&amp;quot;(.+)(Cnr.+,)&amp;quot;, &amp;quot;\\1&amp;quot;, addr_re)
  
  # Add Australia though it seems unnecessary
  addr_re &amp;lt;- paste(addr_re, &amp;quot;Australia&amp;quot;)
  
  # Now run the service.
  gcres &amp;lt;- geocode(addr_re, output=&amp;quot;latlon&amp;quot;)
  
  # Code not shown: run code twice on separate days,
  # since we go over the API use limit.
  write.csv(gcres, latcache, row.names=FALSE) 
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The next step is to get rid of USA addresses, since when geocode does not find a good match, Google returns some random address in the USA (even when we paste ‘Australia’ at the end!). Better approaches exist here, like the geonames service to find the country code, and filter that way, but here this suffices.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;locs &amp;lt;- read.csv(latcache, stringsAsFactors = FALSE) %&amp;gt;%
  filter(lon &amp;gt; 120) %&amp;gt;%
  dplyr::select(-Address_geo)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;distance-to-nearest-competitor&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Distance to nearest competitor&lt;/h2&gt;
&lt;p&gt;Suppose you drive up to a service station and wonder, what if I drive to the next station because it might be cheaper? If there are many choices for you, competition between service stations will be more intense and we should see a lower price at the pump. The next step is then to calculate the distance to the nearest station, as a potential predictor for fuel price.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(sp)
library(rgeos)
library(geosphere)

# Copy of simple dataframe &amp;#39;locs&amp;#39;, to a SpatialPointsDataframe.
# Note how we assign new variables to &amp;#39;locs&amp;#39;, which is a simple 
# dataframe.
locs_sp &amp;lt;- locs
coordinates(locs_sp) &amp;lt;- ~lon+lat

# From geosphere, the correct way to calculate distances between spatial coordinates.
geo_dist &amp;lt;- distm(locs_sp)

# How many other service stations &amp;lt;5km away
countd &amp;lt;- function(x, dist)length(x[x &amp;lt; dist])
locs$nr_5km &amp;lt;- apply(geo_dist, 1, countd, d = 5000)

# Dist to nearest service station
min2 &amp;lt;- function(x)min(x[x &amp;gt; 0])  # exclude self; x &amp;gt; 0 
locs$dist_1 &amp;lt;- apply(geo_dist, 1, min2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The distance to the nearest next service station peaks at 1km (1000m). The most remote service station appears to be 28 Columbus Street, Ivanhoe NSW 2878, though recall that geocoding failed for some stations, so we don’t have distance to all stations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hist(log10(locs$dist_1), breaks=100, axes=FALSE,
     main=&amp;quot;&amp;quot;, col=&amp;quot;cornflowerblue&amp;quot;,
     xlab=&amp;quot;Distance to nearest service station (m)&amp;quot;)
magicaxis::magaxis(side=1, unlog=1)
axis(2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-01-24-fuelprices1_files/figure-html/hist_dist_1-1.png&#34; width=&#34;500px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;area-served-voronoi-polygons&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Area served : Voronoi polygons&lt;/h2&gt;
&lt;p&gt;Related to the above is the idea that each station ‘serves’ a particular area of the state. Think of a polygon around each service station, if you are inside this polygon then that service station is the closest to your location. These polygons are known as Voronoi polygons, and are easily computed in R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(deldir)
voro_plain &amp;lt;- deldir(locs$lon, locs$lat)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I say easily, but the edge effects are massive! Clearly this is not the desired result, and as always a reminder to always visualize your analysis to make sure you did not do something stupid.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mar=c(3,3,1,1))
plot(voro_plain, wlines=&amp;quot;tess&amp;quot;, wpoints=&amp;quot;real&amp;quot;, 
     lty=1, col=c(&amp;quot;black&amp;quot;,&amp;quot;grey&amp;quot;,&amp;quot;red&amp;quot;,&amp;quot;black&amp;quot;,&amp;quot;black&amp;quot;),
     cex=0.6, xlab=&amp;quot;&amp;quot;, ylab=&amp;quot;&amp;quot;)
box()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-01-24-fuelprices1_files/figure-html/voro_plain_fig-1.png&#34; width=&#34;700px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Instead we will use the New South Wales border to trim the Voronoi polygons. This is not an ideal solution either, since stations will be competing with stations on the other side of each border (for which we have no data), but it is an improvement on the above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Make NSW polygon
# Similar to oz::oz(), but coordinates are ordered by state.
oz2 &amp;lt;- read.csv(&amp;quot;http://www.remkoduursma.com/files/ozdata.csv&amp;quot;)
nsw &amp;lt;- filter(oz2, state == &amp;quot;NSW&amp;quot;) %&amp;gt;%
  dplyr::select(long, lat) %&amp;gt;% as.data.frame

# Convert to SpatialPolygonsDataframe
coordinates(nsw) &amp;lt;- ~long + lat
nswp &amp;lt;- Polygon(nsw)
nswpg &amp;lt;- SpatialPolygons(list(Polygons(list(NSW=nswp), &amp;quot;NSW&amp;quot;)))

# Using a zero-width buffer cleans up many topology problems in R.
nswpg &amp;lt;- rgeos::gBuffer(nswpg, byid=TRUE, width=0)

# We use the coordinates returned by voronoi to assign voronoi
# areas for each service station, because for some reason a few dozen 
# polygons cannot be computed (so simple cbind is not possible).
coorsx &amp;lt;- voro_plain$summary[,c(&amp;quot;x&amp;quot;,&amp;quot;y&amp;quot;)]
coordinates(coorsx) &amp;lt;- ~x+y

# Voronoi polygons with a 
library(SDraw)
vp &amp;lt;- voronoi.polygons(coorsx)
voro_buffer &amp;lt;- gIntersection(vp, nswpg, byid=TRUE)

# Now lookup area of each polygon
# We have to do this the hard way, because not all polygons
# are returned (perhaps some failed?).
get_area &amp;lt;- function(point, spoly){
  g &amp;lt;- gContains(spoly, point, byid=TRUE)
  if(any(g)){
    pol &amp;lt;- spoly[which(g)]
    if(!is.null(pol)){
      geosphere::areaPolygon(pol)
    }
  } else {
    NA
  }
}

# Loop through points, look up Voronoi polygon areas.
# Note that `apply` won&amp;#39;t work with a SpatialPointsDataframe,
# at least not like this.
area &amp;lt;- c()
for(i in 1:length(locs_sp))area[i] &amp;lt;- get_area(locs_sp[i,], spoly=voro_buffer)

# Add to &amp;#39;locs&amp;#39; dataframe with locations of Service Stations.
locs$area_voronoi &amp;lt;- area&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(voro_buffer, col=&amp;quot;lightgrey&amp;quot;)
with(locs, points(lon, lat, pch=16, col=scales::alpha(&amp;quot;red&amp;quot;,0.5), cex=0.5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-01-24-fuelprices1_files/figure-html/voro_plot1-1.png&#34; width=&#34;700px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The figure below shows each service station, colored by the ‘area served’ (i.e. the area of the Voronoi polygon), with more yellow indicating smaller areas.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggmap)

nsw_map &amp;lt;- get_map(c(lon = 147.5, lat = -32.5), 
                    source = &amp;quot;google&amp;quot;, zoom=6, maptype=&amp;quot;terrain&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Map from URL : http://maps.googleapis.com/maps/api/staticmap?center=-32.5,147.5&amp;amp;zoom=6&amp;amp;size=640x640&amp;amp;scale=2&amp;amp;maptype=terrain&amp;amp;language=en-EN&amp;amp;sensor=false&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggmap(nsw_map) + 
  geom_point(aes(x=lon, y=lat, col=log10(area_voronoi+1)), data=locs) +
  scale_colour_gradientn(colours=rev(heat.colors(10))) + 
  theme(legend.position = &amp;quot;none&amp;quot;) +
  geom_path(aes(x=long, y=lat), data=as.data.frame(nsw), col=&amp;quot;darkgrey&amp;quot;, lwd=0.6) +
  labs(x=&amp;quot;&amp;quot;, y=&amp;quot;&amp;quot;, caption=&amp;quot;Service stations coloured by area served (Voronoi polygons)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-01-24-fuelprices1_files/figure-html/buffer_voronoi_fig-1.png&#34; width=&#34;700px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;remoteness-distance-to-coast&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Remoteness, distance to coast&lt;/h2&gt;
&lt;p&gt;Eventually I want to build a model that predicts fuel price based on location, and time of year. To do so, we have to start adding some features of interest. The Atlas of Living Australia provides a ‘remoteness index’, which seems interesting since at first sight fuel prices are much higher for more remote locations. Though the ALA provides API services, I did this the quick way by visiting &lt;a href=&#34;http://spatial.ala.org.au/webportal/&#34;&gt;this page&lt;/a&gt;, uploading a CSV with lat and long, and downloading a CSV file with a remoteness index, and the distance to coast. You can read more about how the (unitless) remoteness index is &lt;a href=&#34;http://spatial.ala.org.au/layers/more/aria&#34;&gt;calculated here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(janitor)

# Subset of one date, to get unique locations only.
# The ALA service wants a Date added to the dataframe,
# since remoteness is a time-dependent variable. 
locsub &amp;lt;- filter(locs, lon, lat) %&amp;gt;%
  mutate(eventDate = &amp;quot;2016-6-1&amp;quot;)

# Save to disk...
write.csv(locsub, &amp;quot;data/NSW_fuel_locations_lonlatonly.csv&amp;quot;, row.names=FALSE)

# ... so that it can be uploaded at the ALA:
# http://spatial.ala.org.au/webportal//#
# See that page for help on how to select variables. I just picked
# &amp;#39;remoteness&amp;#39;, and distance to coast, which I saved again locally:
remo &amp;lt;- read.csv(&amp;quot;data/NSW_fuel_ALA_remoteness_locations.csv&amp;quot;, stringsAsFactors = FALSE) %&amp;gt;%
  clean_names %&amp;gt;%
  dplyr::select(locality, latitude_original, longitude_original,
                remoteness_index, distance_to_coast) %&amp;gt;%
  rename(Address = locality,
         lat = latitude_original,
         lon = longitude_original,
         remoteness = remoteness_index,
         dist_to_coast = distance_to_coast) %&amp;gt;%
  mutate(dist_to_coast = 100 * dist_to_coast)
write.csv(remo, &amp;quot;data/NSW_fuel_ALA_remoteness_locations_cleaned.csv&amp;quot;, row.names=F)

# And merge onto &amp;#39;locs&amp;#39;.
remo_m &amp;lt;- dplyr::select(remo, Address, remoteness, dist_to_coast)
locs &amp;lt;- left_join(locs, remo_m, by=&amp;quot;Address&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A plot of New South Wales, where every service station is colored by its ‘remoteness index’,&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Figure
library(oz)
oz(sections=c(4, 13:15), col=&amp;quot;darkgrey&amp;quot;)
cols &amp;lt;- colorRampPalette(c(&amp;quot;yellow&amp;quot;,&amp;quot;darkorange&amp;quot;,&amp;quot;red&amp;quot;))(10)
with(locs, 
     points(lon,lat, pch=21, cex=0.95, col=&amp;quot;white&amp;quot;,
            bg=cols[cut(log(remoteness+1), 10)]))
title(main = &amp;quot;Darker colour = more remote&amp;quot;, line=1, cex.main=0.8, 
      adj=0, font.main=3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-01-24-fuelprices1_files/figure-html/remote_fig1-1.png&#34; width=&#34;600px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Shares some features with the median fuel price, which I first calculate for each service station:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;u91_mean_dat &amp;lt;- filter(fuel, FuelCode == &amp;quot;U91&amp;quot;) %&amp;gt;%
  group_by(Address) %&amp;gt;%
  dplyr::summarize(Price = median(Price, na.rm=TRUE),
                   lon = first(lon), lat=first(lat),
                   Brand = first(Brand),
                   remote = mean(remoteness),
                   nr_5km = mean(nr_5km),
                   dist_1 = mean(dist_1)
                   ) %&amp;gt;%
  filter(Price &amp;lt; 160) %&amp;gt;%
  mutate(Brand = forcats::fct_lump(as.factor(Brand), 6))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-01-24-fuelprices1_files/figure-html/remote_fig2-1.png&#34; width=&#34;600px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And finally we see some relationship between the median fuel price recorded for each station (for just U91 fuel, for now), and the remoteness index of the station. We also see some effect of the brand, with ‘Metro Fuel’ (which serves Sydney, Newcastle mostly) the cheaptes, and Coles Express quickly becoming expensive in slightly more remote locations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(u91_mean_dat, aes(x=remote, y=Price, group=Brand, col=Brand)) +
  geom_point() +
  geom_smooth(method=&amp;quot;lm&amp;quot;, se=F) +
  theme_bw() + 
  theme(
    legend.position = c(.95, .05),
    legend.justification = c(&amp;quot;right&amp;quot;, &amp;quot;bottom&amp;quot;),
    legend.box.just = &amp;quot;right&amp;quot;,
    legend.margin = margin(6, 6, 6, 6)
  ) +
  scale_colour_manual(values=RColorBrewer::brewer.pal(7,&amp;quot;Set3&amp;quot;)) +
  labs(x=&amp;quot;Remoteness index&amp;quot;, y=&amp;quot;Median fuel price (U91) ($ cents)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-01-24-fuelprices1_files/figure-html/remote_price_fig-1.png&#34; width=&#34;600px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see another interesting relationship with the number of service stations in a 5km radius; the fuel price drops quickly when more service stations are added. However, there is a lot of variation particularly for low number of stations. Presumably other factors like distance from the supplier, affluence of the region, will come into play as well.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-01-24-fuelprices1_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;600px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;So far, I spent most of my time cleaning and organizing the data, obtaining spatial coordinates of the stations, and some basic exploration of spatial patterns. I was able to show that fuel is cheaper in less remote, more competitive environments - but many questions remain on what drives the variation in fuel prices. To be continued.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Fuel prices in New South Wales - Part 2</title>
      <link>/post/2018-01-24-fuelprices2/</link>
      <pubDate>Wed, 24 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018-01-24-fuelprices2/</guid>
      <description>&lt;p&gt;It is no secret that gasoline and diesel prices at the pump vary from day to day and from one place to the next. Few people are aware though that a typical pattern in fuel prices looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-01-24-fuelprices2_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;600px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.9news.com.au/national/2018/01/10/19/51/the-reason-why-petrol-30-cents-more-expensive-in-some-sydney-suburbs&#34;&gt;Newspaper articles&lt;/a&gt; have written about this pattern, &lt;a href=&#34;https://www.accc.gov.au/consumers/petrol-diesel-lpg/petrol-price-cycles#petrol-prices-in-sydney&#34;&gt;web services&lt;/a&gt; exist that show where you are on the cycle, and you can compare main cities across Australia. In Sydney, the cycle is about 30 days long (more about that later), and the timing of the spike increase in fuel (which takes only 2-3 days) varies little from pump to pump.&lt;/p&gt;
&lt;p&gt;I have lots of questions about this cycle! This post will take the next step in analyzing a large open source dataset on fuel prices across New South Wales. &lt;a href=&#34;http://www.remkoduursma.com/post/2018-01-24-fuelprices1/&#34;&gt;Read my previous post&lt;/a&gt; about obtaining and cleaning the dataset and some broad spatial patterns, and visit &lt;a href=&#34;https://github.com/remkoDuursma/fuelpricensw&#34;&gt;this github repository&lt;/a&gt; for an R package with the cleaned dataset (and some basic spatial attributes of the stations).&lt;/p&gt;
&lt;p&gt;From this point on I will focus largely on service stations in the greater Sydney area. The reason is that the reporting frequency on fuel prices is higher than remote NSW - usually daily -and because there are lots of service stations in Sydney alone (&amp;gt;750). This analysis - that I work on in my free time - is still well in the exploratory data analysis stage. I have many ideas for follow-up analyses, modelling, and so on - but these will depend on how much time I will have to spend on this topic!&lt;/p&gt;
&lt;p&gt;This is an R blog, so all the below will not just show results but also the code used to generate them. You can find this reproducible document by following &lt;a href=&#34;https://github.com/RemkoDuursma/remkoweb/blob/master/content/post/2018-01-24-fuelprices2.Rmd&#34;&gt;this direct link.&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;the-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The data&lt;/h3&gt;
&lt;p&gt;The data are stored in &lt;a href=&#34;https://github.com/remkoduursma/fuelpricensw&#34;&gt;this R package&lt;/a&gt; (not on CRAN), once installed we can do:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(fuelpricensw)
library(dplyr)

# Merge spatial attributes
fuel &amp;lt;- left_join(fuel, fuelstations, by = &amp;quot;Address&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first step is to select all Sydney stations. I did this by drawing an awkward polygon that captures most the of more densely populated bits (because ‘Greater Sydney’ shapefiles include lots of national parks, many more remote areas, etc.), and deciding whether some station falls in the polygon.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggmap)
library(sp)

# Map tile for background.
syd_map &amp;lt;- ggmap::get_map(c(lon = 151, lat=-33.8), zoom=10)

# Manually entered polygon for &amp;#39;Sydney&amp;#39;, excluding blue mountains etc.
syd_vert &amp;lt;- read.table(text=&amp;quot;
                   lon lat
                   150.65 -34.1
                   150.65 -33.55
                   150.9 -33.55
                   151 -33.7
                   151.35 -33.7
                   151.27 -34.15
                   150.95 -33.95
                   150.8 -34.1&amp;quot;,header=TRUE)


# Select stations in this polygon
in_syd &amp;lt;- sp::point.in.polygon(fuelstations$lon, fuelstations$lat,
                           syd_vert$lon, syd_vert$lat)
locsyd &amp;lt;- fuelstations[in_syd == 1,]

# Also add Brand (BP, shell, etc) to the locations dataframe.
fuelkey &amp;lt;- dplyr::select(fuel, Address, Brand, Postcode) %&amp;gt;% distinct
locsyd &amp;lt;- left_join(locsyd, fuelkey, by=&amp;quot;Address&amp;quot;)


# Sydney data
fuelsyd &amp;lt;- filter(fuel, Address %in% locsyd$Address)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A simple map shows the service stations, using the excellent &lt;code&gt;ggmap&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggmap(syd_map) + 
  geom_polygon(aes(x=lon,y=lat), data=syd_vert, alpha=0.2) +
  geom_point(aes(x=lon, y=lat), data=locsyd, size=0.8, col=&amp;quot;red&amp;quot;) +
  labs(x=&amp;quot;&amp;quot;, y=&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-01-24-fuelprices2_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;600px&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;summarizing-the-ups-and-downs-in-fuel-prices&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Summarizing the ups and downs in fuel prices&lt;/h3&gt;
&lt;p&gt;Next we are going to summarize the fuel price cycles into timings of ‘price hikes’ (the sudden increase in price), the time between cycles (time to reach the minimum counting from the maximum), the time between the minimum and the maximum, the rate of decrease of price between the cycles, and so on.&lt;/p&gt;
&lt;p&gt;To do this, I am going to approximate the fuel price timeseries by a saw pattern - by only considering the minimum and maximum fuel prices reached for each cycle. See the below figure for a few examples.&lt;/p&gt;
&lt;p&gt;The code I developed for this analysis is quite long, and pretty terrible. One issue is that the data have to be cleaned in a variety of ways (short spikes in the data mess up any simple approach).&lt;/p&gt;
&lt;p&gt;In the following I will only consider one of 11 fuel types, U91 (Unleaded petrol, 91 octane), the most commonly reported fuel in the database.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# ... U91 only
fuelu91syd &amp;lt;- filter(fuelsyd, FuelCode == &amp;quot;U91&amp;quot;)

# List of dataframes, one timeseries for each service station. 
# I still prefer this approach over purrr or whatever.
fuelu91syds &amp;lt;- split(fuelu91syd, fuelu91syd$Address)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We then apply our custom magic function to the timeseries for each of 773 service stations in Sydney.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Using dplyr we can write some seriously concise code.
# Using fct_lump, combine rare brands into &amp;#39;Other&amp;#39;
cycsyd &amp;lt;- lapply(fuelu91syds, make_cycledf) %&amp;gt;%
  bind_rows %&amp;gt;% 
  left_join(locsyd, by=&amp;quot;Address&amp;quot;) %&amp;gt;%
  filter(ndata_cycle &amp;gt; 5, price_hike &amp;gt; 5) %&amp;gt;% 
  mutate(Brand2 = forcats::fct_lump(as.factor(Brand), 6))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s one of them:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-01-24-fuelprices2_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;600px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The red points are the peak prices, just after the price hike has occurred, the blue symbols the minimum price reached during this cycle - just before the price hike.&lt;/p&gt;
&lt;p&gt;Finally I prepare a dataset with the cycles themselves summarized, simply by averaging price hikes, median prices at the minimum of the cycles, and so on.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cycsyd_a &amp;lt;- group_by(cycsyd, Address) %&amp;gt;%
  summarize(price_hike_median = median(price_hike, na.rm=T),
            price_peak_median = median(price_peak, na.rm=T),
            price_low_median = median(price_low, na.rm=T),
            ndays_cycle_median = median(ndays_cycle),
            dpricedt = mean(dpricedt),
            lon = mean(lon), lat=mean(lat), 
            nr_5km = mean(nr_5km),
            Brand = first(Brand),
            Brand2 = first(Brand2),
            Postcode = first(Postcode)
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can investigate the average ‘bottom prices’ (blue dots in the figure above), and the average ‘peak prices’ across Sydney, grouped by the different brands of service stations. Here I use the fun &lt;code&gt;ggridges&lt;/code&gt; packages to make semi-overlapping grouped density plots.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(reshape2)
library(forcats)
library(ggridges)

brand_colours &amp;lt;- RColorBrewer::brewer.pal(7,&amp;quot;Set3&amp;quot;)

datsub &amp;lt;- dplyr::select(cycsyd_a, Brand2, price_peak_median, price_low_median) %&amp;gt;%
  melt(id.var = &amp;quot;Brand2&amp;quot;) %&amp;gt;%
 mutate(variable = fct_recode(variable, &amp;quot;peak&amp;quot;=&amp;quot;price_peak_median&amp;quot;,
                              &amp;quot;low&amp;quot;=&amp;quot;price_low_median&amp;quot;),
        Brand2 = reorder(as.factor(Brand2), value, median))  
                      
ggplot(datsub, aes(y=Brand2)) +
  geom_density_ridges(aes(x=value, fill=paste(Brand2, variable)),
                      color=&amp;quot;dimgrey&amp;quot;, alpha=0.8) +
  theme_tufte() + 
  labs(x=&amp;quot;Price (c)&amp;quot;, y=&amp;quot;&amp;quot;) +
  ggtitle(&amp;quot;Bottom price                                   Peak price&amp;quot;) +
  theme(legend.position=&amp;quot;none&amp;quot;)  + 
  scale_fill_manual(values=rep(brand_colours, each=2))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Picking joint bandwidth of 0.909&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2018-01-24-fuelprices2_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;600px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The results quite clearly show that Metro Fuel is the cheapest of the lot, as well as Independent, which makes up a large chunk of the ‘Other’ category in the figure. Prices are otherwise remarkably similar between the brands associated with large corporations.&lt;/p&gt;
&lt;p&gt;That’s it for now. Next up is a closer look at the &lt;em&gt;timing&lt;/em&gt; of price hikes. Stay tuned!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
